"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[30],{4389:function(e,t,a){a.r(t),a.d(t,{frontMatter:function(){return o},contentTitle:function(){return s},metadata:function(){return p},toc:function(){return d},default:function(){return m}});var n=a(7462),r=a(3366),l=(a(7294),a(3905)),i=["components"],o={sidebar_position:1},s="On Premises",p={unversionedId:"manual/onprem",id:"manual/onprem",isDocsHomePage:!1,title:"On Premises",description:"Here you will find a recipe of manual actions how to set up k8s cluster for Deploy locally with help of an operator.",source:"@site/docs/manual/onprem.md",sourceDirName:"manual",slug:"/manual/onprem",permalink:"/xl-deploy-kubernetes-operator/docs/manual/onprem",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Scaffolding",permalink:"/xl-deploy-kubernetes-operator/docs/scaffolding"},next:{title:"AWS OpenShift",permalink:"/xl-deploy-kubernetes-operator/docs/manual/openshift"}},d=[{value:"Troubleshooting",id:"troubleshooting",children:[{value:"Scenario 1",id:"scenario-1",children:[],level:3},{value:"Scenario 2",id:"scenario-2",children:[],level:3},{value:"Scenario 3",id:"scenario-3",children:[],level:3},{value:"Scenario 4",id:"scenario-4",children:[],level:3}],level:2},{value:"Uninstall",id:"uninstall",children:[],level:2}],c={toc:d};function m(e){var t=e.components,o=(0,r.Z)(e,i);return(0,l.kt)("wrapper",(0,n.Z)({},c,o,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"on-premises"},"On Premises"),(0,l.kt)("p",null,"Here you will find a recipe of manual actions how to set up k8s cluster for Deploy locally with help of an operator.\nIt will be described how to do it on ",(0,l.kt)("inlineCode",{parentName:"p"},"minikube"),". If you use another tool, you might need to do it a bit differently."),(0,l.kt)("p",null,"If you already had installed minikube as docker based, first you might have to clean it up with:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"minikube stop; minikube delete &&\ndocker stop $(docker ps -aq) &&\nrm -rf ~/.kube ~/.minikube &&\nsudo rm -rf /usr/local/bin/localkube /usr/local/bin/minikube &&\nlaunchctl stop '*kubelet*.mount' &&\nlaunchctl stop localkube.service &&\nlaunchctl disable localkube.service &&\nsudo rm -rf /etc/kubernetes/ &&\ndocker system prune -af --volumes\n")),(0,l.kt)("p",null,"First of all you have to run ",(0,l.kt)("inlineCode",{parentName:"p"},"minikube")," as VM. "),(0,l.kt)("p",null,"Example:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"minikube start --driver=virtualbox -p k120 --kubernetes-version=v1.20.0\n")),(0,l.kt)("p",null,"We will need Ingress, so we have to install addons to enable it, as it doesn't come with a default setup:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"minikube addons enable ingress\nminikube addons enable ingress-dns\n")),(0,l.kt)("p",null,"Next you have to define a resolvable hostname in ",(0,l.kt)("inlineCode",{parentName:"p"},"/etc/hosts"),", for example like:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-text"},"192.168.59.101 k120\n")),(0,l.kt)("p",null,"where ",(0,l.kt)("inlineCode",{parentName:"p"},"192.168.59.101")," you have to change with the result of ",(0,l.kt)("inlineCode",{parentName:"p"},"minikube -p k120 ip")," "),(0,l.kt)("p",null,"Then you can use ",(0,l.kt)("inlineCode",{parentName:"p"},"k120")," as a hostname for k8s cluster."),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Go through the process of ",(0,l.kt)("a",{parentName:"li",href:"/xl-deploy-kubernetes-operator/docs/scaffolding"},"scaffolding"),".\nAfter following these instructions, you'll get on your filesystem the next structure:")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-text"},"bnechyporenko@Bogdan-Nechyporenko xld % ls -al\ntotal 472\ndrwxr-xr-x  10 bnechyporenko  staff     320 Nov  1 09:40 .\ndrwxr-xr-x   4 bnechyporenko  staff     128 Nov  3 13:43 ..\n-rw-r--r--   1 bnechyporenko  staff     126 Nov  1 09:40 .gitignore\n-rw-r--r--   1 bnechyporenko  staff     194 Nov  1 09:40 Dockerfile\n-rw-r--r--   1 bnechyporenko  staff    7558 Nov  1 09:40 Makefile\n-rw-------   1 bnechyporenko  staff     325 Nov  1 09:41 PROJECT\ndrwx------  10 bnechyporenko  staff     320 Nov  1 09:41 config\ndrwxr-xr-x   3 bnechyporenko  staff      96 Nov  1 09:41 helm-charts\n-rw-r--r--   1 bnechyporenko  staff     198 Nov  1 09:41 watches.yaml\n-rw-r--r--   1 bnechyporenko  staff  214732 Nov  1 09:36 xld.tgz\n")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Create some folder where you can copy and configure the setup. For example ",(0,l.kt)("inlineCode",{parentName:"li"},"xld-operator-setup"),". "),(0,l.kt)("li",{parentName:"ul"},"Copy ",(0,l.kt)("inlineCode",{parentName:"li"},"config")," folder to ",(0,l.kt)("inlineCode",{parentName:"li"},"xld-operator-setup"),". You need only the next 11 files, the rest you can remove:")),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Name"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Path"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},"cluster-role-digital-proxy-role.yaml"),(0,l.kt)("td",{parentName:"tr",align:"center"},"config/rbac/auth_proxy_role.yaml")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},"cluster-role-manager-role.yaml"),(0,l.kt)("td",{parentName:"tr",align:"center"},"config/rbac/role.yaml")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},"cluster-role-metrics-reader.yaml"),(0,l.kt)("td",{parentName:"tr",align:"center"},"config/rbac/auth_proxy_client_clusterrole.yaml")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},"controller-manager-metrics-service.yaml"),(0,l.kt)("td",{parentName:"tr",align:"center"},"config/rbac/auth_proxy_service.yaml")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},"custom-resource-definition.yaml"),(0,l.kt)("td",{parentName:"tr",align:"center"},"config/crd/bases/xld.my.domain_xldeployhelmcharts.yaml")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},"deployment.yaml"),(0,l.kt)("td",{parentName:"tr",align:"center"},"config/default/manager_auth_proxy_patch.yaml")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},"leader-election-role.yaml"),(0,l.kt)("td",{parentName:"tr",align:"center"},"config/rbac/leader_election_role.yaml")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},"leader-election-rolebinding.yaml"),(0,l.kt)("td",{parentName:"tr",align:"center"},"config/rbac/leader_election_role_binding.yaml")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},"manager-rolebinding.yaml"),(0,l.kt)("td",{parentName:"tr",align:"center"},"config/rbac/role_binding.yaml")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},"proxy-rolebinding.yaml"),(0,l.kt)("td",{parentName:"tr",align:"center"},"config/rbac/auth_proxy_role_binding.yaml")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},"daideploy_cr.yaml"),(0,l.kt)("td",{parentName:"tr",align:"center"},"config/samles/xld_v1alpha1_digitalaideploy.yaml")))),(0,l.kt)("p",null,"That mapping has to be applied in ",(0,l.kt)("inlineCode",{parentName:"p"},"applications.yaml")," file. There you can find 10 references to a file, which initially\npoints to a template. Example:"),(0,l.kt)("p",null,(0,l.kt)("inlineCode",{parentName:"p"},'file: !file "kubernetes/template/manager-rolebinding.yaml"')),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Next step is to configure locally Deploy. Make sure, that you have installed Kubernetes plugin. "),(0,l.kt)("li",{parentName:"ul"},"First we will manually create infrastructure CI in Deploy to make sure, that provided values are working against a local\ncluster. I will describe how to do it for a ",(0,l.kt)("inlineCode",{parentName:"li"},"minikube"),", so if you are using something else, some technical details can\nbe a bit different, but the idea is the same. ",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Start creating CI with type k8s.Master ",(0,l.kt)("img",{alt:"k8s master ci creation",src:a(7085).Z})),(0,l.kt)("li",{parentName:"ul"},"Fill in ",(0,l.kt)("inlineCode",{parentName:"li"},"API server URL")," field:\n",(0,l.kt)("img",{alt:"api server url",src:a(4085).Z}),"\nThe command to get your server API:\n",(0,l.kt)("img",{alt:"k8s cluster info",src:a(576).Z})),(0,l.kt)("li",{parentName:"ul"},"Next 3 fields are regarding the certifications. Therefore we have first to find the place where they are located. As\nit depends on which profile is activated. Check it with a command ",(0,l.kt)("inlineCode",{parentName:"li"},"minikube profile"),". For example for me, the active profile\nis ",(0,l.kt)("inlineCode",{parentName:"li"},"minikube"),", and my certificates are located at:")))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-text"},"bnechyporenko@Bogdan-Nechyporenko minikube % ls -al ~/.minikube/profiles/minikube\ntotal 88\ndrwxr-xr-x  12 bnechyporenko  staff   384 Nov  3 13:57 .\ndrwxr-xr-x   5 bnechyporenko  staff   160 Nov  1 09:41 ..\n-rw-r--r--   1 bnechyporenko  staff  1399 Nov  1 09:42 apiserver.crt\n-rw-r--r--   1 bnechyporenko  staff  1399 Nov  1 09:42 apiserver.crt.c7fa3a9e\n-rw-------   1 bnechyporenko  staff  1679 Nov  1 09:42 apiserver.key\n...\n")),(0,l.kt)("p",null,"and one more in a home directory of ",(0,l.kt)("inlineCode",{parentName:"p"},"minikube")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-text"},"bnechyporenko@Bogdan-Nechyporenko minikube % ls -al ~/.minikube\ntotal 56\ndrwxr-xr-x  19 bnechyporenko  staff   608 Nov  3 13:57 .\ndrwxr-xr-x+ 85 bnechyporenko  staff  2720 Nov  4 10:19 ..\ndrwxr-xr-x   2 bnechyporenko  staff    64 Oct 25 15:54 addons\ndrwxr-xr-x   3 bnechyporenko  staff    96 Oct 27 10:12 bin\n-rw-r--r--   1 bnechyporenko  staff  1111 Oct 25 15:56 ca.crt\n-rw-------   1 bnechyporenko  staff  1679 Oct 25 15:56 ca.key\n-rwxr-xr-x   1 bnechyporenko  staff  1099 Nov  3 13:57 ca.pem\n...\n")),(0,l.kt)("p",null,"Knowing all this information, we can fill in next fields:"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:"center"},"Field name"),(0,l.kt)("th",{parentName:"tr",align:"center"},"Path to the cert"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},"caCert"),(0,l.kt)("td",{parentName:"tr",align:"center"},"~/.minikube/ca.crt")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},"tlsCert"),(0,l.kt)("td",{parentName:"tr",align:"center"},"~/.minikube/profiles/minikube/apiserver.crt")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:"center"},"tlsPrivateKey"),(0,l.kt)("td",{parentName:"tr",align:"center"},"~/.minikube/profiles/minikube/apiserver.key")))),(0,l.kt)("div",{className:"admonition admonition-tip alert alert--success"},(0,l.kt)("div",{parentName:"div",className:"admonition-heading"},(0,l.kt)("h5",{parentName:"div"},(0,l.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,l.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"},(0,l.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"}))),"tip")),(0,l.kt)("div",{parentName:"div",className:"admonition-content"},(0,l.kt)("p",{parentName:"div"},"You have to provide in the field not a path, but a content.",(0,l.kt)("br",{parentName:"p"}),"\n","Example: ",(0,l.kt)("img",{alt:"k8s-cert-fill-in-example",src:a(5477).Z})))),(0,l.kt)("p",null,'After that we have to verify if the provided configuration is correct, and we can connect to the cluster. For that\nwe will use a control task "Check Connection".\n',(0,l.kt)("img",{alt:"k8s-check-connection",src:a(9546).Z})),(0,l.kt)("p",null,"If everything configured correctly, you should see something like this:\n",(0,l.kt)("img",{alt:"k8s-successful-connection",src:a(6251).Z})),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"After this success we are ready to fill in the next Yaml file ",(0,l.kt)("inlineCode",{parentName:"p"},"infrastructure.yaml"),"\nFill in here these 4 fields: ",(0,l.kt)("inlineCode",{parentName:"p"},"apiServerURL"),", ",(0,l.kt)("inlineCode",{parentName:"p"},"caCert"),", ",(0,l.kt)("inlineCode",{parentName:"p"},"tlsCert")," and ",(0,l.kt)("inlineCode",{parentName:"p"},"tlsPrivateKey"),". ")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Next step is to verify that no mistakes happened during copy-pasting to ",(0,l.kt)("inlineCode",{parentName:"p"},"infrastructure.yaml"),". For that we need to use\n",(0,l.kt)("a",{parentName:"p",href:"https://docs.xebialabs.com/v.10.2/deploy/concept/get-started-with-devops-as-code/"},"As Code")," feature\nof Deploy to create CIs with help of ",(0,l.kt)("a",{parentName:"p",href:"https://docs.xebialabs.com/v.10.2/deploy/how-to/install-the-xl-cli/"},"XL CLI"),".\nPlease check ",(0,l.kt)("a",{parentName:"p",href:"https://docs.xebialabs.com/v.10.2/deploy/how-to/install-the-xl-cli/"},"XL CLI")," how to install it.\nRun ",(0,l.kt)("inlineCode",{parentName:"p"},"xl apply -f infrastructure.yaml")," by being in the same directory, or specify the full path to the file. In case you\nhave non-default URL, you have to add this parameter: ",(0,l.kt)("inlineCode",{parentName:"p"},"--xl-deploy-url YOUR_XL_DEPLOY_URL"),"\n")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("p",{parentName:"li"},"Next thing to tailor few parameters in ",(0,l.kt)("inlineCode",{parentName:"p"},"xld_v1alpha1_digitalaideploy.yaml"),". Copy it from scaffolding folder (you can find it in ",(0,l.kt)("inlineCode",{parentName:"p"},"config/samples")," folder) to a root of ",(0,l.kt)("inlineCode",{parentName:"p"},"xld-operator-setup")," folder."),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Define or comment  ",(0,l.kt)("inlineCode",{parentName:"li"},"KeystorePassphrase")," and ",(0,l.kt)("inlineCode",{parentName:"li"},"RepositoryKeystore")),(0,l.kt)("li",{parentName:"ul"},"Change StorageClass to what you have. For example, you can use 'standard', in case of using local file system.\nIt depends ",(0,l.kt)("a",{parentName:"li",href:"https://xebialabs.github.io/xl-deploy-kubernetes-helm-chart/docs/installing-storage-class"},"how you configured it"),". "),(0,l.kt)("li",{parentName:"ul"},"Define your license in ",(0,l.kt)("inlineCode",{parentName:"li"},"xldLicense")," field, by converting ",(0,l.kt)("inlineCode",{parentName:"li"},"deployit-license.lic")," file's content to base64."),(0,l.kt)("li",{parentName:"ul"},"Define ",(0,l.kt)("inlineCode",{parentName:"li"},"RepositoryKeystore")," as ",(0,l.kt)("inlineCode",{parentName:"li"},"zs7OzgAAAAIAAAABAAAAAwAWZGVwbG95aXQtcGFzc3N3b3JkLWtleQAAAX0FGMZRrO0ABXNyADNjb20uc3VuLmNyeXB0by5wcm92aWRlci5TZWFsZWRPYmplY3RGb3JLZXlQcm90ZWN0b3LNV8pZ5zC7UwIAAHhyABlqYXZheC5jcnlwdG8uU2VhbGVkT2JqZWN0PjY9psO3VHACAARbAA1lbmNvZGVkUGFyYW1zdAACW0JbABBlbmNyeXB0ZWRDb250ZW50cQB+AAJMAAlwYXJhbXNBbGd0ABJMamF2YS9sYW5nL1N0cmluZztMAAdzZWFsQWxncQB+AAN4cHVyAAJbQqzzF/gGCFTgAgAAeHAAAAARMA8ECHAyz3pefALRAgMDDUB1cQB+AAUAAACQb6Y2JUQqkd5PtdwIAKEWNiVMcTnIS85U7FsvOb+b+xfOCV8+disezZCQ2f4F6YVGRO++u+NXd0YNDn/eXwge4w7i4ewNBydpMSTpVJieJA3nhh7mvUktatsAV+H7EcGYeMPx/cAlkqyFUHuiGz9p1ft3pxmxey2Uyt/FiBgAiV2hZAj14vGdSoRsMH8qN5ECdAAWUEJFV2l0aE1ENUFuZFRyaXBsZURFU3QAFlBCRVdpdGhNRDVBbmRUcmlwbGVERVO9rqwVmysM6czWLFdUj1+Xh1hxHQ=="),". (It's a working dummy example, you are free to use what you wish)"),(0,l.kt)("li",{parentName:"ul"},"Define ",(0,l.kt)("inlineCode",{parentName:"li"},"KeystorePassphrase")," as ",(0,l.kt)("inlineCode",{parentName:"li"},"deployit"),". (It's a working dummy example, you are free to use what you wish)"),(0,l.kt)("li",{parentName:"ul"},'Change namespaces in all yaml files to "default", instead of "system"'),(0,l.kt)("li",{parentName:"ul"},"Change for all ",(0,l.kt)("inlineCode",{parentName:"li"},"kind: ServiceAccount")," the name to ",(0,l.kt)("inlineCode",{parentName:"li"},"default"),"."),(0,l.kt)("li",{parentName:"ul"},"Replace the content of ",(0,l.kt)("inlineCode",{parentName:"li"},"manager_auth_proxy_patch.yaml")," to:")))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    control-plane: controller-manager\n  name: xld-operator-controller-manager\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      control-plane: controller-manager\n  template:\n    metadata:\n      labels:\n        control-plane: controller-manager\n    spec:\n      containers:\n        - name: kube-rbac-proxy\n          image: gcr.io/kubebuilder/kube-rbac-proxy:v0.8.0\n          args:\n            - "--secure-listen-address=0.0.0.0:8443"\n            - "--upstream=http://127.0.0.1:8080/"\n            - "--logtostderr=true"\n            - "--v=10"\n          ports:\n            - containerPort: 8443\n              name: https\n        - name: manager\n          args:\n            - "--health-probe-bind-address=:8081"\n            - "--metrics-bind-address=127.0.0.1:8080"\n            - "--leader-elect"\n            - "--leader-election-id=xld-operator-controller-manager"\n          image: xebialabs/deploy-operator:1.2.0\n          livenessProbe:\n            httpGet:\n              path: /readyz\n              port: 8081\n            initialDelaySeconds: 15\n            periodSeconds: 20\n          readinessProbe:\n            httpGet:\n              path: /healthz\n              port: 8081\n            initialDelaySeconds: 5\n            periodSeconds: 10\n          resources:\n            limits:\n              cpu: 100m\n              memory: 90Mi\n            requests:\n              cpu: 100m\n              memory: 60Mi\n      terminationGracePeriodSeconds: 10\n')),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Now you are ready to run the complete configuration with:\n",(0,l.kt)("inlineCode",{parentName:"li"},"xl apply -v -f digital-ai.yaml"))),(0,l.kt)("h2",{id:"troubleshooting"},"Troubleshooting"),(0,l.kt)("h3",{id:"scenario-1"},"Scenario 1"),(0,l.kt)("p",null,"Run ",(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("inlineCode",{parentName:"strong"},"kubectl get all"))," returns only the Operator control manager pods which are deployed on the Kubernetes cluster. No other pods are deployed.\nThen verify the operator control pod logs ",(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("inlineCode",{parentName:"strong"},"kubectl logs --follow pod/xld-operator-controller-manager-7ccc778f55-nfhl5 -c manger"))," to identify the error in the cr file.\nIf the below error is observed, then remove enabled: true from podSecurityContext tag in ",(0,l.kt)("inlineCode",{parentName:"p"},"xld_v1alpha1_digitalaideploy.yaml"),"."),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"k8s-podSecurity-error",src:a(1237).Z})),(0,l.kt)("h3",{id:"scenario-2"},"Scenario 2"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Step 1")," Run ",(0,l.kt)("strong",{parentName:"li"},(0,l.kt)("inlineCode",{parentName:"strong"},"kubectl get all"))," returns the pods, when the below error is observed in master pod, execute step 2 below.")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"k8s-master-pod-error",src:a(8054).Z})),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Step 2")," Run ",(0,l.kt)("strong",{parentName:"li"},(0,l.kt)("inlineCode",{parentName:"strong"},"kubectl describe pod/digitalaideploy-sample-digitalai-deploy-master-0"))," command to identify the issue in container creation.\nWhen the below error is observed, then define ",(0,l.kt)("inlineCode",{parentName:"li"},"RepositoryKeystore")," and ",(0,l.kt)("inlineCode",{parentName:"li"},"KeystorePassphrase")," ",(0,l.kt)("inlineCode",{parentName:"li"},"xld_v1alpha1_digitalaideploy.yaml"),".")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"k8s-master-pod-describe",src:a(2040).Z})),(0,l.kt)("h3",{id:"scenario-3"},"Scenario 3"),(0,l.kt)("p",null,"Run ",(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("inlineCode",{parentName:"strong"},"kubectl get all"))," and if you see ",(0,l.kt)("inlineCode",{parentName:"p"},"pod/digitalaideploy-sample-nginx-ingress-controller-default-bav88kd")," pod is failing again and again,\ncheck the pod logs ",(0,l.kt)("strong",{parentName:"p"},(0,l.kt)("inlineCode",{parentName:"strong"},"kubectl logs --follow pod/digitalaideploy-sample-nginx-ingress-controller-default-bav88kd"))," for error,\nand when the below error is observed, update the path to ",(0,l.kt)("inlineCode",{parentName:"p"},"/")," for livenessProbe and readinessProbe of ",(0,l.kt)("inlineCode",{parentName:"p"},"nginx-ingress-controller")," in ",(0,l.kt)("inlineCode",{parentName:"p"},"xld_v1alpha1_digitalaideploy.yaml"),"."),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"k8s-nginxController-default-error",src:a(2314).Z})),(0,l.kt)("h3",{id:"scenario-4"},"Scenario 4"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Run ",(0,l.kt)("strong",{parentName:"li"},(0,l.kt)("inlineCode",{parentName:"strong"},"kubectl get all"))," and if your master and worker instance is not starting."),(0,l.kt)("li",{parentName:"ul"},"Change the ",(0,l.kt)("inlineCode",{parentName:"li"},"XldMasterPvcSize: 2Gi")," and ",(0,l.kt)("inlineCode",{parentName:"li"},"XldWorkerPvcSize: 2Gi")," in xld_v1alpha1_digitalaideploy.yaml."),(0,l.kt)("li",{parentName:"ul"},"Verify number of cpus and memory allocated for kubernetes using below command, and if necessary increase the memory and cpus as part of minikube startup ",(0,l.kt)("inlineCode",{parentName:"li"},"minikube start --driver=docker --kubernetes-version=v1.20.0 -p k120 --cpus=4 --memory=15600MB"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},'  [sishwarya@localhost deploy-operator-onprem] $ kubectl get node k120 -o jsonpath=\'{.status.capacity}\'\n        {"cpu":"8","ephemeral-storage":"51175Mi","hugepages-1Gi":"0","hugepages-2Mi":"0","memory":"32301572Ki","pods":"110"}\n')),(0,l.kt)("h2",{id:"uninstall"},"Uninstall"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Perform undeploy of operator in Deploy"),(0,l.kt)("li",{parentName:"ul"},"Remove manually all other CIs left in Deploy"),(0,l.kt)("li",{parentName:"ul"},"Clean PVCs manually")),(0,l.kt)("p",null,"First you have to check what PVC were created"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"bnechyporenko@Bogdan-Nechyporenko k120 % kubectl get pvc\nNAME                                         STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\ndata-dai-xld-postgresql-0                    Bound    pvc-225272f8-f690-40fd-be5f-98d28c874e17   50Gi       RWO            standard       23m\ndata-dai-xld-rabbitmq-0                      Bound    pvc-b0580680-e119-41f9-961b-ab344170a654   8Gi        RWO            standard       23m\ndata-dir-dai-xld-digitalai-deploy-master-0   Bound    pvc-1bfb745b-b451-4103-881c-3e9995033203   10Gi       RWO            standard       23m\ndata-dir-dai-xld-digitalai-deploy-worker-0   Bound    pvc-a1ee162a-da5f-4eb9-8346-5ef3e006861f   10Gi       RWO            standard       23m\n")),(0,l.kt)("p",null,"Afterwards, remove it like that:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-shell",metastring:"script",script:!0},"bnechyporenko@Bogdan-Nechyporenko k120 % kubectl delete pvc data-dai-xld-postgresql-0 data-dai-xld-rabbitmq-0 data-dir-dai-xld-digitalai-deploy-master-0 data-dir-dai-xld-digitalai-deploy-worker-0\n")))}m.isMDXComponent=!0},4085:function(e,t,a){t.Z=a.p+"assets/images/api-server-url-bead8067e4be135f5071f383764425e2.png"},5477:function(e,t,a){t.Z=a.p+"assets/images/k8s-cert-fill-in-example-c3099acaa871279301e936eb469020e4.png"},9546:function(e,t,a){t.Z=a.p+"assets/images/k8s-check-connection-545b3242b3694f957d8e0d13388b2f9e.png"},576:function(e,t,a){t.Z=a.p+"assets/images/k8s-cluster-info-2149229c3ca5f65723d4545d9d298e59.png"},2040:function(e,t,a){t.Z=a.p+"assets/images/k8s-master-pod-describe-9cd0874f82198441173f28acb0bb6f2a.png"},8054:function(e,t,a){t.Z=a.p+"assets/images/k8s-master-pod-error-9b0d50172278949352894d8b5164aa1e.png"},2314:function(e,t,a){t.Z=a.p+"assets/images/k8s-nginxController-default-error-927f2bcc1ba684044509672ac8898185.png"},1237:function(e,t,a){t.Z=a.p+"assets/images/k8s-podSecurity-error-31246342eecc2075f00e5c8d34e57da0.png"},6251:function(e,t,a){t.Z=a.p+"assets/images/k8s-successful-connection-7a08a9e6587128cce89499ac3ca2367d.png"},7085:function(e,t,a){t.Z=a.p+"assets/images/k8smaster-ci-creation-fd6d16b1c743d1e1c60ac6e133f925c5.png"}}]);