# Deploy Kubernetes Operator

## Steps to generate Deploy scaffolding using the Deploy Helm chart

**Note: Before you proceed you should be connected to your Kubernetes cluster**

1. Create a folder namely 'xld'
    ```
    mkdir xld
    ```
2. Switch to xld folder
    ```
    cd xld
    ```
3. Clone the Deploy Helm chart repository
    ```
    git clone git@github.com:xebialabs/xl-deploy-kubernetes-helm-chart.git
    ```
4. Switch to the cloned repository folder
    ```
    cd xl-deploy-kubernetes-helm-chart
    ```
5. Remove the values file for HAProxy as we will generate the scaffolding with NIGIX support
    ```
    rm -f values-haproxy.yaml
    ```
6. Rename the values file for NGINX to values.yaml
    ```
    mv values-nginx.yaml values.yaml
    ```
7. Update the dependency for the charts
    ```
    helm dependency update .
    ```
8. Remove the lock file generated during updates of charts
    ```
    rm -f Chart.lock
    ```
9. Switch back to the parent folder, you should be in 'xld' folder
    ```
    cd ..
    ```
10. Create the Helm package using the available charts
    ```
    helm package xl-deploy-kubernetes-helm-chart
    ```
11. Remove the folder containing helm charts
    ```
    rm -rf xl-deploy-kubernetes-helm-chart
    ```
12. Rename the tgz file to xld.tgz
    ```
    mv digitalai-deploy-10.1.tgz xld.tgz
    ```
13. Use the operator sdk to initiate Deploy operator project, please make sure you are connected to your Kubernetes cluster otherwise you will get an error
    ```
    operator-sdk init --domain digital.ai --plugins=helm
    ```
14. Create APIs with 'xld' group and using the xld helm chart
    ```
    operator-sdk create api --group=xld --version=v1alpha1 --helm-chart=xld.tgz
    ```
15. We now need to generate the operator controller image. Export one variable to create the image along with tag
    ```
    export OPERATOR_IMG="docker.io/xldevdocker/deploy-operator:1.0.0"
    ```
> If you are regenerating the scaffolding due to changes in helm charts then simply increment/change the image tag

16. Using the Makefile generated by operator sdk, build and push the image to the Docker Hub registry
    ```
    make docker-build docker-push IMG=$OPERATOR_IMG
    ```

### At this stage there could be 2 scenarios:
Scenario 1: You are regenerating the scaffolding due to some changes in underlying helm charts.

Scenario 2: You are generating the scaffolding for the first time.

We would disscuss both the scenarios one by one.

### Scenario 1:

1. Clone the **xl-deploy-kubernetes-operator** GitHub repository 
    ```
    git clone git@github.com:xebialabs/xl-deploy-kubernetes-operator.git
    ```
2. Go to the directory available for your Kubernetes platform. Lets assume we are doing it for Kubernetes on-premise cluster.
    ```
    cd xl-deploy-kubernetes-operator/deploy-operator-onprem
    ```
3. Replace the existing custom resource (CR) file with the newly generated custom resource (CR) file. Substitue the '<PATH>' with actual path from the generated files using operator-sdk binary.
    ```
    cp <PATH>/xld/config/samples/xld_v1alpha1_digitalaideploy.yaml digitalai-deploy/kubernetes/daideploy_cr.yaml
    ```
> The custom resource (CR) file is same what you have as values.yaml in helm repository.
4. Check the git diff for the CR file and keep only the changes you have done in values.yaml of the helm repository. Save the changes.
> Changes done in any other file than values.yaml in helm charts will be encapsulated within the operator controller manager image.

5. Update the operator controller manager deployment to point to the new operator controller manager image.
    - Open the deployment file: 'digitalai-deploy/kubernetes/template/deployment.yaml'.
    - Under the spces.containers section navigate to the container named 'manager'.
    - Change the 'image' to the image and tag generated in previous steps.
    - Save and exit.

6. Finally commit and push your changes after reviewing it using git diff command.

### Scenario 2:

**Note: We are considering that the scaffolding is being generated for Kubernetes on-premise cluster.**

1. Create a folder namely 'deploy-operator-onprem' and switch to it.
    ```
    mkdir deploy-operator-onprem
    cd deploy-operator-onprem
    ```
2. Create a directory structure as given below:
    ```
    .
    └── digitalai-deploy
        └── kubernetes
            └── template
   ```
3. Copy the files used by local DAI Deploy instance to create its infrastructure, applications, environment and deployments to install the production version of DAI Deploy on your Kubernetes cluster.

> We are using DAI Deploy container spinned locally to manage the installation of production version of DAI Deploy on Kubernetes cluster.

4. Copy following yaml files required by local DAI Deploy to 'digitalai-deploy' folder. You can create these files from scratch as per your requirement or can copy from current GitHub repository.
    ```
    applications.yaml
    deployment-cr.yaml
    deployment.yaml
    environment.yaml
    infrastructure.yaml
    ```

> Creating infrastructure.yaml for your Kubernetes cluster will be specific to that platform.
5. Copy the custom resource (CR) file generated by operator-sdk to digitalai-deploy/kubernetes folder.
    ```
    cp <PATH>/xld/config/samples/xld_v1alpha1_digitalaideploy.yaml digitalai-deploy/kubernetes/daideploy_cr.yaml
    ```
6. Copy the files responsible to spin operator controller manager pod and making sure that it has required access to Kubernetes cluster. Copy the files to digitalai-deploy/kubernetes/template folder.
    ```
    cp <PATH>/xld/config/crd/bases/xld.digital.ai_digitalaideploys.yaml digitalai-deploy/kubernetes/template/custom-resource-definition.yaml
    cp <PATH>/xld/config/rbac/auth_proxy_role.yaml digitalai-deploy/kubernetes/template/cluster-role-digital-proxy-role.yaml
    cp <PATH>/xld/config/rbac/role.yaml digitalai-deploy/kubernetes/template/cluster-role-manager-role.yaml
    cp <PATH>/xld/config/rbac/auth_proxy_client_clusterrole.yaml digitalai-deploy/kubernetes/template/cluster-role-metrics-reader.yaml
    cp <PATH>/xld/config/rbac/auth_proxy_service.yaml digitalai-deploy/kubernetes/template/controller-manager-metrics-service.yaml
    cp <PATH>/xld/config/default/manager_auth_proxy_patch.yaml digitalai-deploy/kubernetes/template/deployment.yaml
    cp <PATH>/xld/config/rbac/leader_election_role.yaml digitalai-deploy/kubernetes/template/leader-election-role.yaml
    cp <PATH>/xld/config/rbac/leader_election_role_binding.yaml digitalai-deploy/kubernetes/template/leader-election-rolebinding.yaml
    cp <PATH>/xld/config/rbac/role_binding.yaml digitalai-deploy/kubernetes/template/manager-rolebinding.yaml
    cp <PATH>/xld/config/rbac/auth_proxy_role_binding.yaml digitalai-deploy/kubernetes/template/proxy-rolebinding.yaml
    ```

> Please note that we are renaming few files while copying them from the location generated by operator-sdk. Renaming these files are optional. If you decide not to rename them then please make sure that the file digitalai-deploy/applications.yaml is updated to use the original names of the file generated by operator-sdk.
7. Create a file 'digital-ai.yaml' and include the files used by local Deploy container.
    ```
    apiVersion: xl/v1
    kind: Import
    metadata:
     imports:
       - digitalai-deploy/infrastructure.yaml
       - digitalai-deploy/environment.yaml
       - digitalai-deploy/applications.yaml
       - digitalai-deploy/deployment.yaml
       - digitalai-deploy/deployment-cr.yaml
```
8. Additionally you can add 'README.md' and can include the command to trigger the deployment using xl binary.
    ```
    xl apply -v -f digital-ai.yaml
    ```

